\hypertarget{classparser_1_1_lexer__t}{}\section{parser\+:\+:Lexer\+\_\+t Class Reference}
\label{classparser_1_1_lexer__t}\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}


{\ttfamily \#include $<$parser.\+h$>$}



Collaboration diagram for parser\+:\+:Lexer\+\_\+t\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparser_1_1_lexer__t__coll__graph}
\end{center}
\end{figure}
\subsection*{Data Structures}
\begin{DoxyCompactItemize}
\item 
struct \hyperlink{structparser_1_1_lexer__t_1_1_lexer_context__t}{Lexer\+Context\+\_\+t}
\end{DoxyCompactItemize}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparser_1_1_lexer__t_a3b619fa6fdaa02aca63a22dfedad9cb1}{Lexer\+\_\+t} (\hyperlink{structparse_tree_1_1_def_file__t}{parse\+Tree\+::\+Def\+File\+\_\+t} $\ast$file\+Obj\+Ptr)
\item 
bool \hyperlink{classparser_1_1_lexer__t_af5667bc29e8f4bfafc60cda984abfbbe}{Is\+Match} (\hyperlink{structparse_tree_1_1_token__t_ac0e6319a9ad80509dd4aa1037ba66096}{parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t} type)
\item 
\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ \hyperlink{classparser_1_1_lexer__t_a1fa20e4800fc1522042e32d52a9de284}{Pull} (\hyperlink{structparse_tree_1_1_token__t_ac0e6319a9ad80509dd4aa1037ba66096}{parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t} type)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a46cd2e9a399c5a86313d8309bf0478d2}{Reset\+To} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$reset\+Token)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_afdc8e2f5af74f9585d2a9e223d478962}{Convert\+To\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a9841a27715698b13db4c822d9ed606ba}{Convert\+To\+Dotted\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr, size\+\_\+t \&dot\+Count)
\item 
\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ \hyperlink{classparser_1_1_lexer__t_a0219fb1d09222120224fbd87560bd5d0}{Find\+Var\+Use} (const std\+::string \&name)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a732f558af4b7232ee1cafec8d87840d2}{Throw\+Exception} (const std\+::string \&message)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_aa4bb9cab015df705b6c0fc52fe0e78e5}{Unexpected\+Char} (const std\+::string \&message)
\end{DoxyCompactItemize}
\subsection*{Data Fields}
\begin{DoxyCompactItemize}
\item 
bool \hyperlink{classparser_1_1_lexer__t_afcfd969aed90e76d994629496d9cf522}{be\+Verbose}
\end{DoxyCompactItemize}
\subsection*{Private Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_acdfc28410c6fa02431dc5b0d8eaf6dfe}{Next\+Token} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a89d6d4662c92c353287d5a1a9d928a87}{Next\+Token\+Or\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_ae1d3fd3836cf0eda071264cf28e72846}{Process\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_acdd9a9b146e32dc1da868295a234b93c}{Process\+Include\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a5614319aa2d55284fb8695ca22f6797e}{Process\+If\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a8fd4065139f3589521658ac1d1406b7f}{Process\+Else\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_aa21e77ed1eb9a6fdb0959ddffd088e0c}{Process\+Elif\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a7c92f55cf52b6571582be6691ea923ea}{Process\+Endif\+Directive} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a3dbb67f205f82cb0da886aa2534a2b6b}{Skip\+To\+Next\+Directive} ()
\item 
\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ \hyperlink{classparser_1_1_lexer__t_a3de63e7ae7038f39c500042dc9aebe4e}{Skip\+Conditional} (bool allow\+Else, bool skip\+Else)
\item 
bool \hyperlink{classparser_1_1_lexer__t_a2d1b3b0db5dc5eb040991c27e359f6ae}{Pull\+And\+Eval\+Bool\+Expression} ()
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a9ca02eebc0abe9c0877c44772cd59265}{Mark\+Vars\+Used} (const std\+::set$<$ std\+::string $>$ \&\hyperlink{classparser_1_1_lexer__t_a1bc0d9834fc7e2824dc22957ab9c3ad6}{used\+Vars}, \hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$using\+Token\+Ptr)
\item 
bool \hyperlink{classparser_1_1_lexer__t_a9f56b93b06b20371543eee7bc0bb4d90}{Is\+Match\+Boolean} ()
\item 
\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ \hyperlink{classparser_1_1_lexer__t_ae36057080263b7637fa2742fbb762997}{Pull\+Raw} (\hyperlink{structparse_tree_1_1_token__t_ac0e6319a9ad80509dd4aa1037ba66096}{parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t} type)
\item 
\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ \hyperlink{classparser_1_1_lexer__t_a66e20b7cbb45b05b51c1c8176d65d318}{Pull\+Token\+Or\+Directive} (\hyperlink{structparse_tree_1_1_token__t_ac0e6319a9ad80509dd4aa1037ba66096}{parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t} type)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a271c290aa5212d3b19c5f92307e84964}{Pull\+Const\+String} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr, const char $\ast$token\+String)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_af053641d6b967e0922bfbd9304e3162c}{Pull\+Whitespace} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_afad4c713158aa2532ac3864606c4ff52}{Pull\+Comment} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a5086073e925e97220e3c359f9ed5e596}{Pull\+Integer} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a3a4c24b60477e4be1683669f35f3a139}{Pull\+Signed\+Integer} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a7b06370f06ca258f96d7dafc61daf8ef}{Pull\+Boolean} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a3eb9c81f3a290c691396c32e91f26b10}{Pull\+Float} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_aa5d78865c41dacdd53e5583a0036e4d2}{Pull\+String} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a2adf3628e5a579881e04f54a02235c64}{Pull\+File\+Permissions} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a45ecae9c19773b954902b27f59c18464}{Pull\+Server\+Ipc\+Option} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a9afcff0c0263af2435b0fd7bf17db634}{Pull\+Client\+Ipc\+Option} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_ab8c5fa6f0f981479c827d85a129fb7b2}{Pull\+Ipc\+Option} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_ab6b0baeee2ac09b41527719eb7a3c31c}{Pull\+Arg} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_aef844d744f2568fe03579f44c680f5cc}{Pull\+File\+Path} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a28b6c868282e0c31aeae91d67d9308b3}{Pull\+File\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a83ac5912deb23251183ba25d333d8573}{Pull\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a70ecad48f80faca7d7c9ef2a17bd15a5}{Pull\+Dotted\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_aced857ba012be93e34e7b646fce7187b}{Pull\+Group\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_abde46bf45d6eba42f3b160d69afd0993}{Pull\+Ipc\+Agent\+Name} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a2b4297ec19cdf9b4d11fee727c026af2}{Pull\+Quoted} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr, char quote\+Char)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a8449d6b2d79f6bc37b59306c238eeb99}{Pull\+Env\+Var} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a7cf14c3c28b8e4a7800a353b0e2baa2b}{Pull\+Md5} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a531bca3310981b9e15e75c5d0aa3ce15}{Pull\+Directive} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a6b2e41e534543875f3527ed90246400a}{Advance\+One\+Character} (\hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$token\+Ptr)
\item 
\hyperlink{_t_e_m_p_l_a_t_e__cdef_8h_ac9c84fa68bbad002983e35ce3663c686}{void} \hyperlink{classparser_1_1_lexer__t_a8256bb13aac4125dd4e7c8cf9c62717e}{Advance\+One\+Character} (std\+::string \&string)
\item 
std\+::string \hyperlink{classparser_1_1_lexer__t_a251ce44c29ccc943402c9d8364cc366c}{Unexpected\+Char\+Error\+Msg} (char unexpected\+Char, size\+\_\+t line\+Num, size\+\_\+t column\+Num, const std\+::string \&message)
\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
std\+::stack$<$ \hyperlink{structparser_1_1_lexer__t_1_1_lexer_context__t}{Lexer\+Context\+\_\+t} $>$ \hyperlink{classparser_1_1_lexer__t_afae84cc96dffa6d100481e254e92fdfb}{context}
\item 
std\+::map$<$ std\+::string, \hyperlink{structparse_tree_1_1_token__t}{parse\+Tree\+::\+Token\+\_\+t} $\ast$ $>$ \hyperlink{classparser_1_1_lexer__t_a1bc0d9834fc7e2824dc22957ab9c3ad6}{used\+Vars}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
Lexical analyzer. 

\subsection{Constructor \& Destructor Documentation}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Lexer\+\_\+t@{Lexer\+\_\+t}}
\index{Lexer\+\_\+t@{Lexer\+\_\+t}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Lexer\+\_\+t(parse\+Tree\+::\+Def\+File\+\_\+t $\ast$file\+Obj\+Ptr)}{Lexer_t(parseTree::DefFile_t *fileObjPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}Lexer\+\_\+t\+::\+Lexer\+\_\+t (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Def\+File\+\_\+t} $\ast$}]{file\+Obj\+Ptr}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a3b619fa6fdaa02aca63a22dfedad9cb1}{}\label{classparser_1_1_lexer__t_a3b619fa6fdaa02aca63a22dfedad9cb1}
Constructor 

\subsection{Member Function Documentation}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Advance\+One\+Character@{Advance\+One\+Character}}
\index{Advance\+One\+Character@{Advance\+One\+Character}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Advance\+One\+Character(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{AdvanceOneCharacter(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Advance\+One\+Character (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a6b2e41e534543875f3527ed90246400a}{}\label{classparser_1_1_lexer__t_a6b2e41e534543875f3527ed90246400a}
Advance the current file position by one character, appending the character into a given token\textquotesingle{}s text value and updating the line and column numbers.


\begin{DoxyExceptions}{Exceptions}
{\em \hyperlink{classmk_1_1_exception__t}{mk\+::\+Exception\+\_\+t}} & if this can\textquotesingle{}t be done. \\
\hline
\end{DoxyExceptions}

\begin{DoxyParams}{Parameters}
{\em token\+Ptr} & Token object to add the character to. \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Advance\+One\+Character@{Advance\+One\+Character}}
\index{Advance\+One\+Character@{Advance\+One\+Character}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Advance\+One\+Character(std\+::string \&string)}{AdvanceOneCharacter(std::string &string)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Advance\+One\+Character (
\begin{DoxyParamCaption}
\item[{std\+::string \&}]{string}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a8256bb13aac4125dd4e7c8cf9c62717e}{}\label{classparser_1_1_lexer__t_a8256bb13aac4125dd4e7c8cf9c62717e}
Advance the current file position by one character, appending the character into a given string and updating the line and column numbers.


\begin{DoxyExceptions}{Exceptions}
{\em \hyperlink{classmk_1_1_exception__t}{mk\+::\+Exception\+\_\+t}} & if this can\textquotesingle{}t be done. \\
\hline
\end{DoxyExceptions}

\begin{DoxyParams}{Parameters}
{\em string} & String to add the character to. \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Convert\+To\+Dotted\+Name@{Convert\+To\+Dotted\+Name}}
\index{Convert\+To\+Dotted\+Name@{Convert\+To\+Dotted\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Convert\+To\+Dotted\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr, size\+\_\+t \&dot\+Count)}{ConvertToDottedName(parseTree::Token_t *tokenPtr, size_t &dotCount)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Convert\+To\+Dotted\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr, }
\item[{size\+\_\+t \&}]{dot\+Count}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a9841a27715698b13db4c822d9ed606ba}{}\label{classparser_1_1_lexer__t_a9841a27715698b13db4c822d9ed606ba}
Attempt to convert a given token to a D\+O\+T\+T\+E\+D\+\_\+\+N\+A\+ME token.


\begin{DoxyExceptions}{Exceptions}
{\em \hyperlink{classmk_1_1_exception__t}{mk\+::\+Exception\+\_\+t}} & if the token contains characters or character sequences that are not allowed in a D\+O\+T\+T\+E\+D\+\_\+\+N\+A\+ME. \\
\hline
\end{DoxyExceptions}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Convert\+To\+Name@{Convert\+To\+Name}}
\index{Convert\+To\+Name@{Convert\+To\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Convert\+To\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{ConvertToName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Convert\+To\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_afdc8e2f5af74f9585d2a9e223d478962}{}\label{classparser_1_1_lexer__t_afdc8e2f5af74f9585d2a9e223d478962}
Attempt to convert a given token to a N\+A\+ME token.


\begin{DoxyExceptions}{Exceptions}
{\em \hyperlink{classmk_1_1_exception__t}{mk\+::\+Exception\+\_\+t}} & if the token contains characters that are not allowed in a N\+A\+ME. \\
\hline
\end{DoxyExceptions}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Find\+Var\+Use@{Find\+Var\+Use}}
\index{Find\+Var\+Use@{Find\+Var\+Use}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Find\+Var\+Use(const std\+::string \&name)}{FindVarUse(const std::string &name)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$ Lexer\+\_\+t\+::\+Find\+Var\+Use (
\begin{DoxyParamCaption}
\item[{const std\+::string \&}]{name}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a0219fb1d09222120224fbd87560bd5d0}{}\label{classparser_1_1_lexer__t_a0219fb1d09222120224fbd87560bd5d0}
Find if an environment or build variable has been used by the lexer.

\begin{DoxyReturn}{Returns}
Pointer to the first token in which the variable was used, or N\+U\+LL if not used. 
\end{DoxyReturn}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Is\+Match@{Is\+Match}}
\index{Is\+Match@{Is\+Match}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Is\+Match(parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t type)}{IsMatch(parseTree::Token_t::Type_t type)}}]{\setlength{\rightskip}{0pt plus 5cm}bool Lexer\+\_\+t\+::\+Is\+Match (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t}}]{type}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_af5667bc29e8f4bfafc60cda984abfbbe}{}\label{classparser_1_1_lexer__t_af5667bc29e8f4bfafc60cda984abfbbe}
Check if the next sequence of text in the file could match a given type of token. 
\begin{DoxyParams}{Parameters}
{\em type} & The type of token to pull from the file. \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Is\+Match\+Boolean@{Is\+Match\+Boolean}}
\index{Is\+Match\+Boolean@{Is\+Match\+Boolean}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Is\+Match\+Boolean()}{IsMatchBoolean()}}]{\setlength{\rightskip}{0pt plus 5cm}bool Lexer\+\_\+t\+::\+Is\+Match\+Boolean (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a9f56b93b06b20371543eee7bc0bb4d90}{}\label{classparser_1_1_lexer__t_a9f56b93b06b20371543eee7bc0bb4d90}
Check if a valid boolean value (true, false, on, or off) is waiting in the input stream.

\begin{DoxyReturn}{Returns}
true if a valid boolean is waiting. false otherwise. 
\end{DoxyReturn}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Mark\+Vars\+Used@{Mark\+Vars\+Used}}
\index{Mark\+Vars\+Used@{Mark\+Vars\+Used}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Mark\+Vars\+Used(const std\+::set$<$ std\+::string $>$ \&used\+Vars, parse\+Tree\+::\+Token\+\_\+t $\ast$using\+Token\+Ptr)}{MarkVarsUsed(const std::set< std::string > &usedVars, parseTree::Token_t *usingTokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Mark\+Vars\+Used (
\begin{DoxyParamCaption}
\item[{const std\+::set$<$ std\+::string $>$ \&}]{local\+Used\+Vars, }
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{using\+Token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a9ca02eebc0abe9c0877c44772cd59265}{}\label{classparser_1_1_lexer__t_a9ca02eebc0abe9c0877c44772cd59265}
Mark some variables as used by the preprocessor.

This prevents these variables from being redefined at a later date to ensure all expansions of a variable see the same value. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Next\+Token@{Next\+Token}}
\index{Next\+Token@{Next\+Token}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Next\+Token()}{NextToken()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Next\+Token (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_acdfc28410c6fa02431dc5b0d8eaf6dfe}{}\label{classparser_1_1_lexer__t_acdfc28410c6fa02431dc5b0d8eaf6dfe}
Move to the start of the next interesting token in the input stream.

Interesting is currently non-\/whitespace, non-\/comment, non-\/directive. Any uninteresting tokens are still added to the token list for the file, but not returned by \hyperlink{classparser_1_1_lexer__t_a1fa20e4800fc1522042e32d52a9de284}{Lexer\+\_\+t\+::\+Pull()}. This function will expand directives in place. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Next\+Token\+Or\+Directive@{Next\+Token\+Or\+Directive}}
\index{Next\+Token\+Or\+Directive@{Next\+Token\+Or\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Next\+Token\+Or\+Directive()}{NextTokenOrDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Next\+Token\+Or\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a89d6d4662c92c353287d5a1a9d928a87}{}\label{classparser_1_1_lexer__t_a89d6d4662c92c353287d5a1a9d928a87}
Move to the start of the next interesting token or directive in the input stream.

Interesting is currently non-\/whitespace, non-\/comment, non-\/directive. Any uninteresting tokens are still added to the token list for the file, but not returned by \hyperlink{classparser_1_1_lexer__t_a1fa20e4800fc1522042e32d52a9de284}{Lexer\+\_\+t\+::\+Pull()}. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+Directive@{Process\+Directive}}
\index{Process\+Directive@{Process\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+Directive()}{ProcessDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_ae1d3fd3836cf0eda071264cf28e72846}{}\label{classparser_1_1_lexer__t_ae1d3fd3836cf0eda071264cf28e72846}
Process a single directive.

The directives supported by mk$\ast$ tools are\+:
\begin{DoxyItemize}
\item \#include \char`\"{}file\char`\"{}\+: Include another file in this one.
\item \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}, \#elif, \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else} and \#endif\+: Conditionally process sections of a file. 
\end{DoxyItemize}\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+Elif\+Directive@{Process\+Elif\+Directive}}
\index{Process\+Elif\+Directive@{Process\+Elif\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+Elif\+Directive()}{ProcessElifDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+Elif\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_aa21e77ed1eb9a6fdb0959ddffd088e0c}{}\label{classparser_1_1_lexer__t_aa21e77ed1eb9a6fdb0959ddffd088e0c}
Process an elif directive.

Since \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif processing skips over any inactive \#elif blocks, this will only be called if this marks the end of an active \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif block. Skip straight to final \#endif. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+Else\+Directive@{Process\+Else\+Directive}}
\index{Process\+Else\+Directive@{Process\+Else\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+Else\+Directive()}{ProcessElseDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+Else\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a8fd4065139f3589521658ac1d1406b7f}{}\label{classparser_1_1_lexer__t_a8fd4065139f3589521658ac1d1406b7f}
Process an else directive.

Since \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif processing skips over any inactive \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else} blocks, this will only be called if this marks the end of an active \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif block. Skip straight to final \#endif. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+Endif\+Directive@{Process\+Endif\+Directive}}
\index{Process\+Endif\+Directive@{Process\+Endif\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+Endif\+Directive()}{ProcessEndifDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+Endif\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a7c92f55cf52b6571582be6691ea923ea}{}\label{classparser_1_1_lexer__t_a7c92f55cf52b6571582be6691ea923ea}
Process an endif directive.

Since \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif processing skips over any inactive \#elif blocks, this will only be called if this marks the end of an active \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if}/\#elif block. Not really important for \#endif though -- always just decrement the nesting depth. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+If\+Directive@{Process\+If\+Directive}}
\index{Process\+If\+Directive@{Process\+If\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+If\+Directive()}{ProcessIfDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+If\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a5614319aa2d55284fb8695ca22f6797e}{}\label{classparser_1_1_lexer__t_a5614319aa2d55284fb8695ca22f6797e}
Process an if directive.

This skips to the start of the active section of the conditional block. A conditional block looks like\+: \begin{DoxyVerb}#if <condition>                // Initial #if statement
    // #if block
    // statements ...
#elif <condition>              // Zero or more
    // #elif block             // #elif blocks
    // statements ...
#else                          // Optional
    // #else block             // #else block
    // statements
#endif                         // Final #endif
\end{DoxyVerb}



\begin{DoxyItemize}
\item Skip nothing if condition on \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if} block is true, otherwise
\item Skip to start of first \#elif block whose condition evaluates to true, otherwise
\item Skip to start of \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else} block, if one exists, finally
\item Skip to statement after \#endif if there\textquotesingle{}s no \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else} block. 
\end{DoxyItemize}\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Process\+Include\+Directive@{Process\+Include\+Directive}}
\index{Process\+Include\+Directive@{Process\+Include\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Process\+Include\+Directive()}{ProcessIncludeDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Process\+Include\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_acdd9a9b146e32dc1da868295a234b93c}{}\label{classparser_1_1_lexer__t_acdd9a9b146e32dc1da868295a234b93c}
Process an include directive. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull@{Pull}}
\index{Pull@{Pull}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull(parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t type)}{Pull(parseTree::Token_t::Type_t type)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$ Lexer\+\_\+t\+::\+Pull (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t}}]{type}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a1fa20e4800fc1522042e32d52a9de284}{}\label{classparser_1_1_lexer__t_a1fa20e4800fc1522042e32d52a9de284}
Pull a token from the file being parsed, moving the point to the start of the next important token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+And\+Eval\+Bool\+Expression@{Pull\+And\+Eval\+Bool\+Expression}}
\index{Pull\+And\+Eval\+Bool\+Expression@{Pull\+And\+Eval\+Bool\+Expression}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+And\+Eval\+Bool\+Expression()}{PullAndEvalBoolExpression()}}]{\setlength{\rightskip}{0pt plus 5cm}bool Lexer\+\_\+t\+::\+Pull\+And\+Eval\+Bool\+Expression (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a2d1b3b0db5dc5eb040991c27e359f6ae}{}\label{classparser_1_1_lexer__t_a2d1b3b0db5dc5eb040991c27e359f6ae}
Pull and evaluate a boolean expression which is recognizable by the preprocessor. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Arg@{Pull\+Arg}}
\index{Pull\+Arg@{Pull\+Arg}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Arg(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullArg(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Arg (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_ab6b0baeee2ac09b41527719eb7a3c31c}{}\label{classparser_1_1_lexer__t_ab6b0baeee2ac09b41527719eb7a3c31c}
Pull a command-\/line argument from the input file and store it in the token.

Performs environment variable substitution before storing the result in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Boolean@{Pull\+Boolean}}
\index{Pull\+Boolean@{Pull\+Boolean}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Boolean(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullBoolean(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Boolean (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a7b06370f06ca258f96d7dafc61daf8ef}{}\label{classparser_1_1_lexer__t_a7b06370f06ca258f96d7dafc61daf8ef}
Pull a boolean value from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Client\+Ipc\+Option@{Pull\+Client\+Ipc\+Option}}
\index{Pull\+Client\+Ipc\+Option@{Pull\+Client\+Ipc\+Option}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Client\+Ipc\+Option(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullClientIpcOption(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Client\+Ipc\+Option (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a9afcff0c0263af2435b0fd7bf17db634}{}\label{classparser_1_1_lexer__t_a9afcff0c0263af2435b0fd7bf17db634}
Pull a client-\/side I\+PC option (e.\+g., \char`\"{}\mbox{[}manual-\/start\mbox{]}\char`\"{}) from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Comment@{Pull\+Comment}}
\index{Pull\+Comment@{Pull\+Comment}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Comment(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullComment(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Comment (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_afad4c713158aa2532ac3864606c4ff52}{}\label{classparser_1_1_lexer__t_afad4c713158aa2532ac3864606c4ff52}
Pull a comment from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Const\+String@{Pull\+Const\+String}}
\index{Pull\+Const\+String@{Pull\+Const\+String}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Const\+String(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr, const char $\ast$token\+String)}{PullConstString(parseTree::Token_t *tokenPtr, const char *tokenString)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Const\+String (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr, }
\item[{const char $\ast$}]{token\+String}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a271c290aa5212d3b19c5f92307e84964}{}\label{classparser_1_1_lexer__t_a271c290aa5212d3b19c5f92307e84964}
Pulls a constant string token from the input stream.


\begin{DoxyExceptions}{Exceptions}
{\em \hyperlink{classmk_1_1_exception__t}{mk\+::\+Exception\+\_\+t}} & if the next token in the stream does not match the string exactly. \\
\hline
\end{DoxyExceptions}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Directive@{Pull\+Directive}}
\index{Pull\+Directive@{Pull\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Directive(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullDirective(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a531bca3310981b9e15e75c5d0aa3ce15}{}\label{classparser_1_1_lexer__t_a531bca3310981b9e15e75c5d0aa3ce15}
Pull a processing directive (e.\+g. include, conditional) from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Dotted\+Name@{Pull\+Dotted\+Name}}
\index{Pull\+Dotted\+Name@{Pull\+Dotted\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Dotted\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullDottedName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Dotted\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a70ecad48f80faca7d7c9ef2a17bd15a5}{}\label{classparser_1_1_lexer__t_a70ecad48f80faca7d7c9ef2a17bd15a5}
Pull a dotted name from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Env\+Var@{Pull\+Env\+Var}}
\index{Pull\+Env\+Var@{Pull\+Env\+Var}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Env\+Var(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullEnvVar(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Env\+Var (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a8449d6b2d79f6bc37b59306c238eeb99}{}\label{classparser_1_1_lexer__t_a8449d6b2d79f6bc37b59306c238eeb99}
Pulls an environment variable out of the input file stream and appends it to a given token.

N\+O\+TE\+: Environment variable substitution is not done here because we want to preserve the token text exactly as it appeared in the file. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+File\+Name@{Pull\+File\+Name}}
\index{Pull\+File\+Name@{Pull\+File\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+File\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullFileName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+File\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a28b6c868282e0c31aeae91d67d9308b3}{}\label{classparser_1_1_lexer__t_a28b6c868282e0c31aeae91d67d9308b3}
Pull a file name from the input file and store it in the token.

Performs environment variable substitution before storing the result in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+File\+Path@{Pull\+File\+Path}}
\index{Pull\+File\+Path@{Pull\+File\+Path}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+File\+Path(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullFilePath(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+File\+Path (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_aef844d744f2568fe03579f44c680f5cc}{}\label{classparser_1_1_lexer__t_aef844d744f2568fe03579f44c680f5cc}
Pull a file path from the input file and store it in the token.

Performs environment variable substitution before storing the result in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+File\+Permissions@{Pull\+File\+Permissions}}
\index{Pull\+File\+Permissions@{Pull\+File\+Permissions}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+File\+Permissions(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullFilePermissions(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+File\+Permissions (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a2adf3628e5a579881e04f54a02235c64}{}\label{classparser_1_1_lexer__t_a2adf3628e5a579881e04f54a02235c64}
Pull file permissions (e.\+g., \char`\"{}\mbox{[}rw\mbox{]}\char`\"{}) from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Float@{Pull\+Float}}
\index{Pull\+Float@{Pull\+Float}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Float(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullFloat(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Float (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a3eb9c81f3a290c691396c32e91f26b10}{}\label{classparser_1_1_lexer__t_a3eb9c81f3a290c691396c32e91f26b10}
Pull a floating point value from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Group\+Name@{Pull\+Group\+Name}}
\index{Pull\+Group\+Name@{Pull\+Group\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Group\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullGroupName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Group\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_aced857ba012be93e34e7b646fce7187b}{}\label{classparser_1_1_lexer__t_aced857ba012be93e34e7b646fce7187b}
Pull a group name from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Integer@{Pull\+Integer}}
\index{Pull\+Integer@{Pull\+Integer}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Integer(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullInteger(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Integer (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a5086073e925e97220e3c359f9ed5e596}{}\label{classparser_1_1_lexer__t_a5086073e925e97220e3c359f9ed5e596}
Pull an integer (possibly ending in a K suffix) from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Ipc\+Agent\+Name@{Pull\+Ipc\+Agent\+Name}}
\index{Pull\+Ipc\+Agent\+Name@{Pull\+Ipc\+Agent\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Ipc\+Agent\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullIpcAgentName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Ipc\+Agent\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_abde46bf45d6eba42f3b160d69afd0993}{}\label{classparser_1_1_lexer__t_abde46bf45d6eba42f3b160d69afd0993}
Pull the name of an I\+PC agent (user or app) from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Ipc\+Option@{Pull\+Ipc\+Option}}
\index{Pull\+Ipc\+Option@{Pull\+Ipc\+Option}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Ipc\+Option(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullIpcOption(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Ipc\+Option (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_ab8c5fa6f0f981479c827d85a129fb7b2}{}\label{classparser_1_1_lexer__t_ab8c5fa6f0f981479c827d85a129fb7b2}
Pull an I\+PC option (e.\+g., \char`\"{}\mbox{[}manual-\/start\mbox{]}\char`\"{}) from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Md5@{Pull\+Md5}}
\index{Pull\+Md5@{Pull\+Md5}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Md5(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullMd5(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Md5 (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a7cf14c3c28b8e4a7800a353b0e2baa2b}{}\label{classparser_1_1_lexer__t_a7cf14c3c28b8e4a7800a353b0e2baa2b}
Pull an \hyperlink{class_m_d5}{M\+D5} hash from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Name@{Pull\+Name}}
\index{Pull\+Name@{Pull\+Name}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Name(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullName(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Name (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a83ac5912deb23251183ba25d333d8573}{}\label{classparser_1_1_lexer__t_a83ac5912deb23251183ba25d333d8573}
Pull a name from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Quoted@{Pull\+Quoted}}
\index{Pull\+Quoted@{Pull\+Quoted}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Quoted(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr, char quote\+Char)}{PullQuoted(parseTree::Token_t *tokenPtr, char quoteChar)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Quoted (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr, }
\item[{char}]{quote\+Char}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a2b4297ec19cdf9b4d11fee727c026af2}{}\label{classparser_1_1_lexer__t_a2b4297ec19cdf9b4d11fee727c026af2}
Pull into a token\textquotesingle{}s text everything up to and including the first occurrence of a given quote character. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Raw@{Pull\+Raw}}
\index{Pull\+Raw@{Pull\+Raw}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Raw(parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t type)}{PullRaw(parseTree::Token_t::Type_t type)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$ Lexer\+\_\+t\+::\+Pull\+Raw (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t}}]{type}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_ae36057080263b7637fa2742fbb762997}{}\label{classparser_1_1_lexer__t_ae36057080263b7637fa2742fbb762997}
Pull a single token from the file being parsed, leaving the point immediately after the token. 
\begin{DoxyParams}{Parameters}
{\em type} & The type of token to pull from the file. \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Server\+Ipc\+Option@{Pull\+Server\+Ipc\+Option}}
\index{Pull\+Server\+Ipc\+Option@{Pull\+Server\+Ipc\+Option}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Server\+Ipc\+Option(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullServerIpcOption(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Server\+Ipc\+Option (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a45ecae9c19773b954902b27f59c18464}{}\label{classparser_1_1_lexer__t_a45ecae9c19773b954902b27f59c18464}
Pull a server-\/side I\+PC option (e.\+g., \char`\"{}\mbox{[}manual-\/start\mbox{]}\char`\"{}) from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Signed\+Integer@{Pull\+Signed\+Integer}}
\index{Pull\+Signed\+Integer@{Pull\+Signed\+Integer}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Signed\+Integer(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullSignedInteger(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Signed\+Integer (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a3a4c24b60477e4be1683669f35f3a139}{}\label{classparser_1_1_lexer__t_a3a4c24b60477e4be1683669f35f3a139}
Pull an integer (possibly ending in a K suffix) from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+String@{Pull\+String}}
\index{Pull\+String@{Pull\+String}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+String(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullString(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+String (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_aa5d78865c41dacdd53e5583a0036e4d2}{}\label{classparser_1_1_lexer__t_aa5d78865c41dacdd53e5583a0036e4d2}
Pull a string literal from the input file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Token\+Or\+Directive@{Pull\+Token\+Or\+Directive}}
\index{Pull\+Token\+Or\+Directive@{Pull\+Token\+Or\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Token\+Or\+Directive(parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t type)}{PullTokenOrDirective(parseTree::Token_t::Type_t type)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$ Lexer\+\_\+t\+::\+Pull\+Token\+Or\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t\+::\+Type\+\_\+t}}]{type}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a66e20b7cbb45b05b51c1c8176d65d318}{}\label{classparser_1_1_lexer__t_a66e20b7cbb45b05b51c1c8176d65d318}
Pull a token or directive from the file being parsed, moving the point to the start of the next token or directive. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Pull\+Whitespace@{Pull\+Whitespace}}
\index{Pull\+Whitespace@{Pull\+Whitespace}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Pull\+Whitespace(parse\+Tree\+::\+Token\+\_\+t $\ast$token\+Ptr)}{PullWhitespace(parseTree::Token_t *tokenPtr)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Pull\+Whitespace (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{token\+Ptr}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_af053641d6b967e0922bfbd9304e3162c}{}\label{classparser_1_1_lexer__t_af053641d6b967e0922bfbd9304e3162c}
Pull a sequence of whitespace characters from the file and store it in the token. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Reset\+To@{Reset\+To}}
\index{Reset\+To@{Reset\+To}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Reset\+To(parse\+Tree\+::\+Token\+\_\+t $\ast$reset\+Token)}{ResetTo(parseTree::Token_t *resetToken)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Reset\+To (
\begin{DoxyParamCaption}
\item[{{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$}]{reset\+Token\+Ptr}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a46cd2e9a399c5a86313d8309bf0478d2}{}\label{classparser_1_1_lexer__t_a46cd2e9a399c5a86313d8309bf0478d2}
Reset lexer back to state immedately after the given token.

No pointers can be retained to tokens which are reset, as these tokens will be deleted. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Skip\+Conditional@{Skip\+Conditional}}
\index{Skip\+Conditional@{Skip\+Conditional}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Skip\+Conditional(bool allow\+Else, bool skip\+Else)}{SkipConditional(bool allowElse, bool skipElse)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf parse\+Tree\+::\+Token\+\_\+t} $\ast$ Lexer\+\_\+t\+::\+Skip\+Conditional (
\begin{DoxyParamCaption}
\item[{bool}]{allow\+Else, }
\item[{bool}]{skip\+Else}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a3de63e7ae7038f39c500042dc9aebe4e}{}\label{classparser_1_1_lexer__t_a3de63e7ae7038f39c500042dc9aebe4e}
Skip until the end of a conditional section.

There are three cases where a section is skipped\+:

Case 1\+: hit false expression; skip to start of next condition. \begin{DoxyVerb}#if <false expression>  //<-- currently here
    // statements
#elif //<-- skip to here, returning this #elif token
      //    (could also be #else or #endif directive)
\end{DoxyVerb}


Case 2a\+: hit end of \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if} or \#elif block terminated by an \#elif; skip to \#endif. \begin{DoxyVerb}#if <true expression>
    // statements
#elif //<-- currently here
    // statements
#elif
    // statements
#else
    // statements
#endif //<-- skip to here, returning #endif token.  #elif and #else allowed to be skipped.
\end{DoxyVerb}


Case 2b\+: Hit \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if} in section being skipped. Skip straight to \#endif. \begin{DoxyVerb}#if <false condition>
    #if //<-- currently here
        // statements
    #else
        // statements
    #endif //<-- skip to here.
\end{DoxyVerb}


Case 3\+: Hit end of \hyperlink{wifi_web_ap_8c_a2bf420bda7cb80e4552dcff350cddbef}{if} or \#elif block terminated by an \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else}. Skip to \#endif. \begin{DoxyVerb}#if <true condition>
    // statements
#else //<-- currently here
    // statements
#endif //<-- skip to here.  #elif and #else are not allowed as an #else has already been
       //    seen.
\end{DoxyVerb}


\begin{DoxyReturn}{Returns}
the token that ends the conditional section 
\end{DoxyReturn}

\begin{DoxyParams}{Parameters}
{\em allow\+Else} & Is \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else} or \#elif allowed? \\
\hline
{\em skip\+Else} & Skip over \hyperlink{xattr_8c_a0544c3fe466e421738dae463968b70ba}{else}/\#elif sections, straight to final \#endif? \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Skip\+To\+Next\+Directive@{Skip\+To\+Next\+Directive}}
\index{Skip\+To\+Next\+Directive@{Skip\+To\+Next\+Directive}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Skip\+To\+Next\+Directive()}{SkipToNextDirective()}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Skip\+To\+Next\+Directive (
\begin{DoxyParamCaption}
\item[{{\bf void}}]{}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a3dbb67f205f82cb0da886aa2534a2b6b}{}\label{classparser_1_1_lexer__t_a3dbb67f205f82cb0da886aa2534a2b6b}
Skip over a single token, regardless of the type.

This only skips non-\/whitespace tokens. To skip whitespace or comments, use \hyperlink{classparser_1_1_lexer__t_acdfc28410c6fa02431dc5b0d8eaf6dfe}{Next\+Token()}.

\begin{DoxyNote}{Note}
This function does minimal validation on the pulled token, so may allow invalid tokens. 
\end{DoxyNote}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Throw\+Exception@{Throw\+Exception}}
\index{Throw\+Exception@{Throw\+Exception}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Throw\+Exception(const std\+::string \&message)}{ThrowException(const std::string &message)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Throw\+Exception (
\begin{DoxyParamCaption}
\item[{const std\+::string \&}]{message}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_a732f558af4b7232ee1cafec8d87840d2}{}\label{classparser_1_1_lexer__t_a732f558af4b7232ee1cafec8d87840d2}
Throws an exception containing the file path, line number, and column number, in the same style as a compiler would. \index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Unexpected\+Char@{Unexpected\+Char}}
\index{Unexpected\+Char@{Unexpected\+Char}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Unexpected\+Char(const std\+::string \&message)}{UnexpectedChar(const std::string &message)}}]{\setlength{\rightskip}{0pt plus 5cm}{\bf void} Lexer\+\_\+t\+::\+Unexpected\+Char (
\begin{DoxyParamCaption}
\item[{const std\+::string \&}]{message}
\end{DoxyParamCaption}
)}\hypertarget{classparser_1_1_lexer__t_aa4bb9cab015df705b6c0fc52fe0e78e5}{}\label{classparser_1_1_lexer__t_aa4bb9cab015df705b6c0fc52fe0e78e5}
Throws an unexpected character exception containing the file path, line number, column number, and information about the unexpected character. 
\begin{DoxyParams}{Parameters}
{\em message} & Additional info to append to the exception message. \\
\hline
\end{DoxyParams}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!Unexpected\+Char\+Error\+Msg@{Unexpected\+Char\+Error\+Msg}}
\index{Unexpected\+Char\+Error\+Msg@{Unexpected\+Char\+Error\+Msg}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{Unexpected\+Char\+Error\+Msg(char unexpected\+Char, size\+\_\+t line\+Num, size\+\_\+t column\+Num, const std\+::string \&message)}{UnexpectedCharErrorMsg(char unexpectedChar, size_t lineNum, size_t columnNum, const std::string &message)}}]{\setlength{\rightskip}{0pt plus 5cm}std\+::string Lexer\+\_\+t\+::\+Unexpected\+Char\+Error\+Msg (
\begin{DoxyParamCaption}
\item[{char}]{unexpected\+Char, }
\item[{size\+\_\+t}]{line\+Num, }
\item[{size\+\_\+t}]{column\+Num, }
\item[{const std\+::string \&}]{message}
\end{DoxyParamCaption}
)\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a251ce44c29ccc943402c9d8364cc366c}{}\label{classparser_1_1_lexer__t_a251ce44c29ccc943402c9d8364cc366c}
Generate an \char`\"{}\+Unexpected character\char`\"{} error message.

\begin{DoxyReturn}{Returns}
The message. 
\end{DoxyReturn}

\begin{DoxyParams}{Parameters}
{\em message} & Additional message to append. \\
\hline
\end{DoxyParams}


\subsection{Field Documentation}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!be\+Verbose@{be\+Verbose}}
\index{be\+Verbose@{be\+Verbose}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{be\+Verbose}{beVerbose}}]{\setlength{\rightskip}{0pt plus 5cm}bool parser\+::\+Lexer\+\_\+t\+::be\+Verbose}\hypertarget{classparser_1_1_lexer__t_afcfd969aed90e76d994629496d9cf522}{}\label{classparser_1_1_lexer__t_afcfd969aed90e76d994629496d9cf522}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!context@{context}}
\index{context@{context}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{context}{context}}]{\setlength{\rightskip}{0pt plus 5cm}std\+::stack$<${\bf Lexer\+Context\+\_\+t}$>$ parser\+::\+Lexer\+\_\+t\+::context\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_afae84cc96dffa6d100481e254e92fdfb}{}\label{classparser_1_1_lexer__t_afae84cc96dffa6d100481e254e92fdfb}
\index{parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}!used\+Vars@{used\+Vars}}
\index{used\+Vars@{used\+Vars}!parser\+::\+Lexer\+\_\+t@{parser\+::\+Lexer\+\_\+t}}
\subsubsection[{\texorpdfstring{used\+Vars}{usedVars}}]{\setlength{\rightskip}{0pt plus 5cm}std\+::map$<$std\+::string, {\bf parse\+Tree\+::\+Token\+\_\+t}$\ast$$>$ parser\+::\+Lexer\+\_\+t\+::used\+Vars\hspace{0.3cm}{\ttfamily [private]}}\hypertarget{classparser_1_1_lexer__t_a1bc0d9834fc7e2824dc22957ab9c3ad6}{}\label{classparser_1_1_lexer__t_a1bc0d9834fc7e2824dc22957ab9c3ad6}
All variables which have been used by processing directives. These variables should not be overriden or the results may be confusing. 

The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
framework/tools/mk\+Tools/parser/\hyperlink{parser_8h}{parser.\+h}\item 
framework/tools/mk\+Tools/parser/\hyperlink{lexer_8cpp}{lexer.\+cpp}\end{DoxyCompactItemize}
